steps from launching vm

sudo apt-get update

sudo apt-get install default-jdk

sudo apt-get install rsync

sudo apt-get install ssh

ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa


cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorizedkeys

cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys


wget http://apache.mirrors.tds.net/hadoop/common/hadoop-3.2.0/hadoop-3.2.0.tar.gz


ls

sudo tar -xvf hadoop-3.2.0.tar.gz


sudo mv hadoop-3.2.0 /usr/local/hadoop

update-alternatives --config java
( /usr/lib/jvm/java-11-openjdk-amd64/bin/java)  JDK path


ssh localhost (System config)

(Text Editor)
sudo apt-get install vim


sudo vim ~/.bashrc
or
sudo nano ~/.bashrc


#Hadoop Variable

export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeS
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib"
:wq(type save and exit)

(run ~/.bashrc)
source ~/.bashrc

(copy)
sudo cp mapred-site.xml.template mapred-site.xml
or
sudo cp mapred-site.xml mapred-site.xml.backup

(open)
sudo nano mapred-site.xml
<configuration>
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
</configuration>

(open)
sudo nano yarn-site.xml

<configuration>
<property>
<name>yarn.nodemanager.aux-service</name>
<value>mapreduce_shuffle</value>
</property>
</configuration>


(open)
sudo nano core-site.xml

(hdfs file system uses default name, and  portno 9000)
<configuration>
<property>
<name>fs.default.name</name>
<value>hdfs://localhost:9000</value>
</property>
</configuration>

(open)

sudo nano hdfs-site.xml

<configuration>
#DFS file Replication time 1
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
#dfs Name node
<property>
<name>dfs.name.dir</name>
<value>file://home/Akbar/hadoopspace/hdfs/namenode</value>
</property>
#dfs Data node
<property>
<name></name>
<value>file://home/Akbar/hadoopspace/hdfs/namenode/datanode</value>
</property>
</configuration>

(open)
sudo nano hadoop-env.sh

export JAVA_Home="/usr/lib/jv
m/java-11-openjdk-amd64/"
save and exit


cd(local user dir)

pwd(check Path dir)

mkdir -p /home/Akbar/hadoopspace/hdfs/namenode

mkdir -p /home/Akbar/hadoopspace/hdfs/namenode/datanode

(Give admin permission)
sudo chown -R Akbar:Akbar /usr/local/hadoop


















